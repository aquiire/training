I was recruited as a software engineering intern to vcLABs with two of my colleagues of University of Moratuwa, Heshan Fernando and Vidura Sumanasena. We were assigned to improve the current ad detection system.

\section{Tasks Assigned}
The main problem that vcLABs ad detection tool had was the inter-channel ad detection. The tool works perfectly when it comes to detecting ads which are trained from the same channel (intra-channel ad detection). But if it were to detect an ad for which its hash was generated from another channel, it was not able to detect that ad most of the time. Our first task was to create a channel agnostic algorithm for ad detection. We were not explained the existing detection algorithm because it would constrain our ideas. But guidance was given during the tasks by Dr. Madhawa and our supervisors.

I participated in mainly 4 tasks.

\begin{itemize}
\item Developing an algorithm to compare videos
\item Investigating the potential of using Single-shot Multi-box Detector (SSD) model to ad detection in collaboration with one of my colleagues (Heshan Fernando)
\item Investigating the potential of using Siamese architecture to detect ads in collaboration with Heshan Fernando
\item Creating a Error Reporting System to the Current Ad replacement System.
\end{itemize}

\section{Environments Used}
The existing algorithm was coded in c++. As we were expected to familiarize with the current system architecture, we were given some time to get to to know the environment. The input device to the workstation that runs the system was a Decklink SDI 4K card.

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=.4\textwidth]{decklink-sdi-4k.jpg}
		\caption{Decklink SDI 4K Card }.
		\label{fig:deckilink-card}
		\end{center}
\end{figure} 

Decklink SDI 4K card inputs the downstream from the satellite in SDI format which consists raw video and audio data. This card has its own API, with a detailed documentation. I had never referred an API before for development purposes so this was a learning experience for me.

The company used Visual Studio 2013 in their projects so we were encouraged to use it for our projects. 

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=.4\textwidth]{visual_studio_purple.png}
		\caption{Visual Studio 2013 }.
		\label{fig:visual-studio}
		\end{center}
\end{figure}

I wasn't familiar with visual studio before, so there was a learning curve on learning visual studio and c++. 

In addition to Visual Studio, I used \texttt{python} in machine learning tasks as it is currently the leading programming language in machine learning and AI. \texttt{Tensorflow}, \texttt{keras} and \texttt{matplotlib} were the most used modules. In addition I was able to familiarize with \texttt{conda environments} and \texttt{python package manager} called \texttt{pip}.

Most the developments related to machine learning was done on an \texttt{Ubuntu} machine. Meanwhile, I was able to get to know about some basic terminal tasks like activating python environments, using terminal editors like vim, source control using git, etc.

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=.4\textwidth]{software-tools.png}
		\caption{Some other Software Tools Used }.
		\label{fig:software-tools}
		\end{center}
\end{figure}

Seldom I had to use \texttt{docker images} to work with \texttt{caffe}, \texttt{Microsoft Cognitive Toolkit (CNTK)}, \texttt{scikit-learn} and \texttt{OpenAI} in order to get some idea about machine learning frameworks.

\section{Familiarization Programs}
In order to be familiar with Visual Studio Environment, my former supervisor assigned me to develop a simple video player make using \texttt{opencv} in \texttt{c++}. I had to spend almost a week to get \texttt{opencv} working in the Visual Studio Environment. I was given some \texttt{c++} tutorials to follow along with some simple \texttt{opencv} tutorials, ranging from opening an image to detection of an object via a webcam using simple HSV (Hue-Saturation-Value) color-space segmentation.

At the end of the familiarization period I was able to make a command-line video player which can play a given video in a constant frame rate. I made use of \texttt{opencv highgui} framework. To control the frame rate I used a PID controller out of curiosity and it worked fine.

Amidst the training period we shifted to apply machine learning in ad detection task. In order to get comfortable with machine learning, I followed some machine learning tutorials involving both \texttt{tensorflow} and \texttt{keras}. \texttt{Keras} is a \texttt{tensorflow} wrapper but very much simple.

In order to shift from rule based programming to machine learning and AI, I had to move from Microsoft Windows to Ubuntu, which is a linux distribution that is widely used among machine learning community. As there is a huge community, getting problems solved was much easier.

As a requirement to \texttt{tensorflow}, \texttt{NVIDIA CUDA} drivers had to be installed. CUDA gives programmers a chance to write massively parallel programs which makes use of GPU. I had an \texttt{NVIDIA GEFORCE 920M} GPU on my machine so I installed CUDA. I followed some on-line tutorials about CUDA programming so that I could use it for optimization purposes.

During the first month of the training period a black box kind of introduction (without going into details) was given to us by engineers at vcLABs.

\subsection{Field Trip to DialogTV Kotahena}
The actual ad replacement system is in operation at DialogTV Kotahena Establishment. I learned the following facts from this field visit:

\subsubsection{Functions of DialogTV Kotahena}

\begin{itemize}
\item Receiving channels: Foreign channels are received via satellites and via cables and local channels are received from Normal antennas.
\item Process Channels: Processing include audio balancing, video rate matching, etc. and ad replacement and multiplexing.
\item Sending up-link to satellite.
\item Customer care: Taking action on breakdowns, etc. 
\end{itemize}

\subsubsection{Ad Replacement System}

The ad replacement system is operated by the Ad Insertion Unit of DialogTV Engineering Team. Both the old manual system and the new automated system created by vcLABs are under operation in parallel. This Ad Insertion Unit and vcLABs engineering team are in a constant communication in order to develop the system. The Ad Insertion Unit has basically following tasks:

\begin{itemize}
\item Maintaining manual ad insertion
\item Monitor automated ad replacement system
\item Report for bugs in automated ad replacement system to vcLABs engineers.
\end{itemize}

\subsection{Workshop by Dr. Madhawa}

This was held on 30th October 2017 at Cinnamon Lakeside Hotel. That workshop was an eye opener for me. The workshop discussed the following:
\begin{itemize}
\item History of vcLABs
\subitem How vcLABs came in to existence was discussed with the background story metioned in the introduction
\item Current Situation
\subitem Situation of the current projects going on, and the ad replacement system was discussed
\item Future plans
\subitem Future plans to make the company more profitable and useful to Sri Lanka was discussed in detail
\item Operations in other branches
\subitem Dr. Madhawa discussed about the situation about the US branch and the Australia branch including their future projects in the area of machine learning research

\end{itemize}

\section{Video Comparison Algorithm}

\subsection{Introduction}
The most simplest way to compare 2 videos would be to take corresponding frames and take the SSD of the frames and add them up. For an identical video pair, this comparison would give a value of zero. In a way this distance can be considered as the Euclidean distance between the 2 videos.

\begin{equation}
\text{SSD}=\sum_{i=1}^N |F_{i,1}-F_{i,2}|^2
\end{equation}

Here $F_{i,n}$ means the $i$\textsuperscript{th} frame of the video $n$ ($n=1\text{ or } 2$). $N$ is the number of frames in videos. If the resolution of the video is $p\times q$, then $F_{i,n}$ is a $p\times q \times 3$ array because a pixel is described by $3$ values in our case. (e.g. RGB, HSV) 

So if we want to compare videos we simply need to calculate the "Euclidean distance" of the 2 videos. (Here we assume the videos have the same number of frames.) If the $\text{SSD}=0$ we deduce that the videos are the same, otherwise they are not.

But in a practical scenario this is hardly the case. Sometimes videos which are totally different to our perception will result in lower $\text{SSD}$ values than the same video pair. This may happen due to noise added to video in the transmission, processing of videos and other reasons.

So the method I propose intends to have a remedy for that.

\subsection{Description of the Algorithm}

\subsubsection{Rationale}
%For simplicity let's consider 2 pairs of videos with resolution $5\times 5$.
What We perceive in an image is defined by not only individual pixel values but also by the relationship between pixel values.

In our case we need to detect an ad regardless of the channel. For instance, if we find region $A$ darker than region $B$ on a frame of an ad, that would be the case regardless of the channel for the same ad. That was the main principle behind the algorithm.

\subsubsection{Method}
\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=.6\textwidth]{lgo.png}
		\caption{Final Algorithm to Figure out Closeness between 2 Videos }.
		\label{fig:final-algo}
		\end{center}
\end{figure}
Figure \ref{fig:final-algo} sums up the algorithm. \texttt{Frame i}, and \texttt{Frame i+k} on the left belong to one video and that of on the left belong to another. Here what it meant by a \texttt{Frame} can be the original frame of the video as it is or a processed version. For example, the process can be Gaussian Bluring plus downsampling. Nevertheless, all \texttt{Frame}s should be of the same resolution and color space.

\texttt{Transfer} is a function to replace the pixels from its original location. It can be a rotation followed by a resize for instance. Here \texttt{k} should be chosen in order to get a good accuracy plus a speed. Higher \texttt{k} increases the delay and accuracy.

The function denoted by \texttt{1} outputs 2 results. They are \texttt{inc} and \texttt{dec} which are masks. \texttt{inc} keeps track of pixel positions for which pixel value increased from \texttt{rFrame} to \texttt{Frame i+k}. \texttt{dec} keeps track of that of decreased. \texttt{OR}, \texttt{XOR} and \texttt{AND} carry their usual meaning and they are pixel-wise.
% can add more details

The rest of the algorithm is self explanatory except for the function \texttt{f} which gives the final score of how equal the 2 videos are.

\subsection{Results}

\subsubsection{Susceptibility to Gamma-Correction}

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=.4\textwidth]{result-algo-vs-gamma-corrected.png}
		\caption{Confusion matrix of the video similarity between 8 videos and their gamma corrected versions. Here $\sf g\_ads $ axis represents the gamma corrected versions of $\sf ads$ }.
		\label{fig:result-algo-vs-gamma-corrected}
		\end{center}
\end{figure}

The algorithm was check against 8 videos and their Gamma Corrected versions and the confusion matrix of the task is given in Fig. \ref{fig:result-algo-vs-gamma-corrected}.



\subsubsection{Susceptibility to AWGN}

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=.4\textwidth]{result-algo-vs-noise1.png}
		\caption{Confusion matrix of the video similarity between 8 videos and videos for which AWGN with $\sigma=1$ was added. Here $\sf nvids3 $ axis represents the noisy versions of $\sf vids$ }.
		\label{fig:result-algo-vs-noise1}
		\end{center}
\end{figure}

Additive White Gaussian Noise (AWGN) with $\sigma=1$ was added and checked and the results are shown in Fig. \ref{fig:result-algo-vs-noise1}.



\subsection{What's Next?}
The algorithm was tested using python which is not suitable for a real time ad detection system. It should be converted to c++ which is faster than python and for which off the shelf libraries are available to migrate the algorithm to the current ad replacement system.

Most of the functions used in the algorithm are bitwise operations, so that calculation time would be minimized. Since pixel-wise operations are also there platforms such as CUDA can be used for more optimizations.

\subsection{Tools used for the development}

\subsubsection{Python}

Python programming language is a widely used programming language and very easy to use. If more work is to be done in a short amount of time without thinking about maintainability and security, one of the best choices would be python. 

To test my idea of the algorithm it only took very less amount of time. Python has its own package manager which makes thing even more easier. To check the viability of the algorithm, I needed to read videos. For that purpose I just needed to install the necessary package, \texttt{scikit-video} with its dependencies. Then all the documentation and sample codes are freely available online so I was good to go with the algorithm.

\subsubsection{Jupyter Notebook}

Jupyter Notebook is the ideal environment for a person to test things up rather than building a whole system. The interactive nature of Jupyter Notebooks come in handy in many occasions. If someone need to explain something to someone on the go they create their work Jupyter notebook would be the perfect candidate. 

Currently reproducible research is a hot topic in research community. Jupyter Notebook environment is unmatched by many solutions currently available for such purposes. One of the most important aspect of Jupyter Notebooks is that it's open source and free. And one of the key other advantages is that it's accessible remotely. 

Machine Learning and data science community is currently mostly benefited by this tool. Although there are some glitches they are quite insignificant compared to the advantages we could gain from this tool.

The whole algorithm was created and tested on a Jupyter Notebook environment. The key features I used were: 
\begin{itemize}
\item Its inline plotting capability powered by \texttt{matplotlib}
\item Ability to easily incorporate diagrams
\item Ability to incorporate equations
\item Markup functionality to add formatting, e.g:
	\begin{itemize}
	\item Heading Levels
	\item block quotes
	\item Bold italic functionality
	\end{itemize}
\item ability to easily convert to different other formats like:
	\begin{itemize}
	\item pdf
	\item html
	\item Restructured Text Format
	\item markup
	\item latex
	\item slideshows powered by reveal.js
	\item python code (other parts are commented except python code in this format)
	\end{itemize}
\end{itemize}


\subsubsection{FFMPEG}

FFMPEG is highly versatile, command-line tool for tasks related for videos such as:

\begin{itemize}
\item Conversion of videos to different formats / encodings
\item Extracting video frames as images
\item Changing the quality level of the video
\end{itemize}

... and many more. The functions I used most on my path to the algorithm are listed above.

\subsubsection{Numpy}

Numpy is a python library available for numeric / linear algebraic functionality. It has highly optimized algorithms for handling higher dimensional data structures which makes the life easier for a programmer. 

\subsubsection{Matplotlib}

Matplotlib comes in handy for plotting purposes. The sublibrary I used the most is \texttt{matplotlib.pyplot}. Not only plotting, but also the ability to  import images to the workspace, matplotlib can be used.

A pure matlab experience can be achieved free of charge if one has both numpy and matplotlib in my opinion. It is even better if those two were used in a Jupyter notebook.


\section{Investigation on the Potential of Using SSD Model to Detect Ads}

\subsection{Introduction to SSD Model}
SSD (Single Shot Multibox Detector) architecture is one of the state of the art content recognition models currently in the world (Fig. \ref{fig:ssd-arch}). SSD model is a deep convolution neural network (DCNN) that does the following once an image is given as its input.

\begin{itemize}
\item Detect the content of the image: Here the contents are pre-trained
\item Create bounding boxes around the detected content
\item Label the caged content
\end{itemize}

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=\textwidth]{SSD_architecture.pdf}
		\caption{Comparison between the 2 models YOLO and SSD. YOLO was also a content detection algorithm created by Facebook AI reseearch lab and was the superior content recognition system prior to SSD }.
		\label{fig:ssd-arch}
		\end{center}
\end{figure}

YOLO (You Look Only Once), created by Facebook AI research team can be considered as one of the world's first real-time content detection systems. But the SSD architecture proved to be superior than YOLO due to its higher accuracy and higher frame rate. SSD was developed by Google AI research group.

Use of SSD to recognize ads was put forward by Dr. Madhawa Silva on one of our online meetings. Human perception of an advertisement is partially based on the contents that are in the advertisement. Since SSD does the exact thing, that suggests that there is a possibility of using SSD to advertisement detection.

The SSD Model I used was trained on COCO dataset and had a considerable amount of ability to detect contents with the following 20 labels:

Airplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, dinning table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, tv monitor.

\subsection{Metric to Define Distances between Labels}

This task was collaborative done with one of my colleagues at vcLABs, Heshan Fernando. We both were asked to develop out own metric to make use of the output of SSD network in order to generate some hash for ad detection.

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=\textwidth]{ssd-example.pdf}
		\caption{An example of SSD in action }.
		\label{fig:ssd-example}
		\end{center}
\end{figure}

In the process of defining a hash from SSD output, it is a vital part to get the relationship between labels (content categories). For instance question such as "how probable that a picture of a dog can be predicted as sheep?" should be incorporated in to the hash generating method.

I followed the following approach:
\begin{itemize}
\item Investgated SSD internals to get useful data: 
\subitem Rather than final output (e.g. Fig. \ref{fig:ssd-example}) which contains most probable detection I needed to see the level before that, i.e. the level where predictions were given for every 20 labels and for all bounding boxes.
\subitem There were no such things as predefined bounding boxes in the model although 7308 priory boxes are there. 
\subitem The model actually outputs a $7308\times 33$ array for each image it is fed into, i.e. each of the priory box has $33$ values generated
\subitem Out of the $33$ values $20$ confidence values were given for each content type, i.e. label
\subitem Another 4 values were dedicated for the actual location of the bounding box which may or may not be the location of the priory box

\item Created images with different quality levels
\subitem 1000 from each label were downloaded from COCO dataset.(Altogether 20000 images).
\subitem Here I didn't use the existing ad frame for this task because ad frames rarely comprised of the labels that the existing SSD model was trained for. Retraining the model such that it suits for the ad frame database was a tedious task and might be an overkill before understanding the viability of the method.
\subitem All the images were blurred with 10 levels of $\sigma$ values of a Gaussian kernel.
\subitem For each image downloaded 10 quality levels were there.

\item Predictions were generated for each of the quality level such that for each image, an array of $10\times7308\times33$ dimension was outputted.

\item It was observed what happens to predictions with the quality level.
\end{itemize}

\subsubsection{Rationale}
The observations on how predictions change with quality level was done in order to figure out a way to build a relationship among labels. Let's say the quality level changes from $0$ to $9$, from best to worst. What was expected to happen was a label change for on the way of quality level from $0$ to $9$. For instance if for a box, prediction was changed from "dog" to "sheep" that would be an indication that "dog" is much closer label to "sheep" than "kites".

\subsubsection{Algorithm to Create an $n$-dimensional hyper space for labels}
Once the relative distance are given it is able to make a $n$ dimensional hyper space for the 20 labels where each of the label has it's own spot on the hyper space so that easily distance of 2 labels is mapped to just distance of 2 pointsin the hyperspace.

Let's define distances matrix, $D$:

$
D =
 \begin{pmatrix}
  d_{0,0} & d_{0,1} & \cdots & d_{0,n-1} \\
  d_{1,0} & d_{1,1} & \cdots & d_{1,n-1} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  d_{n-1,0} & d_{n-1,1} & \cdots & d_{n-1,n-1}
 \end{pmatrix}
`$

coordinates matrix, $X$:

$
X =
 \begin{pmatrix}
  x_{0,0} & x_{0,1} & \cdots & x_{0,n-2} \\
  x_{1,0} & x_{1,1} & \cdots & x_{1,n-2} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  x_{n-1,0} & x_{n-1,1} & \cdots & x_{n-1,n-2}
 \end{pmatrix}
$

Here, $x_{i,j}$: 
\begin{itemize}
\item $i$: point
\item $j$: axis
\end{itemize}


We first initialise first 2 coordinates as:
\begin{itemize}
\item $P_0\equiv(d_{0,0},)$
\item $P_1\equiv(d_{0,1},)$
\end{itemize}


To figure out $P_2$, we need to solve the 2 equations of circles centered at $P_0$ and $P_1$ whose radii are $d_{0,2}$ and $d_{1,2}$ respectively.

For example:

If,
$
D =
 \begin{pmatrix}
 0 & 1 & 1 & 1 & 1 & 1 \\
 1 & 0 & \sqrt{2} & \sqrt{2} & \sqrt{2} & \sqrt{2} \\
 1 & \sqrt{2} & 0 & \sqrt{2} & \sqrt{2} & \sqrt{2} \\
 1 & \sqrt{2} & \sqrt{2} & 0 & \sqrt{2} & \sqrt{2} \\
 1 & \sqrt{2} & \sqrt{2} & \sqrt{2} & 0 & \sqrt{2} \\
 1 & \sqrt{2} & \sqrt{2} & \sqrt{2} & \sqrt{2} & 0 \\
 \end{pmatrix}
`$

the output should be given by:

$
X =
 \begin{pmatrix}
 0 & 0 & 0 & 0 & 0 \\
 1 & 0 & 0 & 0 & 0 \\
 0 & 1 & 0 & 0 & 0 \\
 0 & 0 & 1 & 0 & 0 \\
 0 & 0 & 0 & 1 & 0 \\
 0 & 0 & 0 & 0 & 1 \\
 \end{pmatrix}
`$


\subsection{What's Next?}
It is necessary to Come up  with a probabilistic algorithm to get the coordinates when perfect information is not available, or the information (distances) available have a confidence value associated with it (i.e. when we are not $100\%$ sure about the distance values)
\subsection{Tools used for this task}
\subsubsection{Python}
Since this tasks comprises machine learning, python is the best option in the field currently. Apart from that some other reasons for python to be the choice given as follows:

\begin{itemize}
\item Faster to get something working
\item Off the shelf modules for almost every task imagined with python
\subitem With just typing \texttt{pip install <package>} many capabilities could be added.
\item Virtual environments
\subitem If we need to approach the dependency barrier, virtual environments is the way to go. For instance if someone needs 2 different versions of the same package for 2 projects they are working on, python provides virtual environments to do that exactly.
\subitem Lots of SSD implementations were there with different dependencies. At some point I had to migrate from tensorflow implementation of SSD to akeras implementation in order to have a clearer  idea about the internals of the code. Since I was using virtual environments I could do it without any trouble
\end{itemize}

\subsubsection{Tensorflow}
Tensorflow can be considered as the most widely used machine learning framework out there in the industry. This was open sourced by Google and helped revolutionizing machine learning, making it available to general public to play around with machine learning. Tensorflow has the following advantages:
\begin{itemize}
\item Community support
\subitem Since there are lots of users using tensorflow, there is lots of support. Just googling an error gives the exactly the solution almost all times.
\subitem Not only in forums but also in the forms of video tutorials, blog tutorials, the support is  available.
\item Comprehensive Documentation
\item Off the shelf pre-trained models
\subitem There is an online repository for different kinds of models from tensorflow itself
\subitem There are also models created by other people which they created themselves or created referring papers
\item Highly optimized code
\subitem tensorflow is highly optimized with the support of platforms such as CUDA,CUDNN, etc. 
\subitem Intel has released its own version of tensorflow which is optimized especially for Intel processors.
\end{itemize}

Although there are lots of advantages, there are some pitfalls too.
\begin{itemize}
\item Somewhat complex abstraction layer
\subitem Tensorflow has it's own method of calculating stuff with defining session, etc. For a new user it takes some time to get the hang of it
\item For a beginner, it would be cumbersome to build his own model
\end{itemize}

\subsubsection{Keras}

Keras is the solution for the complexity of tensorflow. If someone need to create some model as fast as possible keras could be a better solution. Keras can be considered as a wrapper to machine learning frameworks such as tensorflow, theano, CNTK, etc. I used mostly tensorflow as the backend. It doesn't matter what the backend is, because mostly keras implementations would not differ from backend to backend.

Some of the advantages of keras are listed below.

\begin{itemize}
\item Easy-to-understand abstraction layer.
\subitem Model can be built on the go without thinking about other stuff like in tensorflow
\item Community Support
\item Comprehensive documentation
\item Availability of tutorials and models
\subitem  The SSD model I used was already implemented. The authors of the original SSD paper has implemented it using caffe. Caffe is somewhat cumbersome to install. So keras version was taken.
\end{itemize}

Some of the cons of Keras:

\begin{itemize}
\item Less flexibility
\subitem Since keras is just a wrapper, tensorflow internals cannot be changed without knowing the abstractions of tensorflow
\end{itemize}



\section{Investigation on the Potential of Using Siamese Architecture to Detect Ads}
\subsection{Introduction to Siamese Architecture}
Siamese Architecture was first used in 1993 for the task of signature verification as shown in Fig. \ref{fig:siamese-first} which was extracted from the original paper.
\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=\textwidth]{siamese-first.png}
		\caption{The first use of Siamese Architecture }.
		\label{fig:siamese-first}
		\end{center}
\end{figure}

Siamese architecture has the idea of using twin models sharing the mirror image of weights by each other connected from the end to create an output using two inputs. One half of the network we used is shown on Fig. \ref{fig:siamese-used}. Most of the time Siamese architecture is used to figure out whether the inputs are the same or not. Of course siamese architecture can be extended for task of N-way detection.

\begin{figure}[!hbt]
		\begin{center}
		\includegraphics [width=\textwidth]{siamese-used.jpg}
		\caption{One half of the siamese Architecture used}.
		\label{fig:siamese-used}
		\end{center}
\end{figure}

As the task of ad detection can be considered as an "N-way siamese task", Siamese Architecture would be an ideal architecture to use for ad detection as proposed by Dr. Madhawa.

\subsection{Role played}
This investigation was assigned to me and my colleague Heshan Fernando. I was responsible for the following:

\begin{itemize}
\item Creating the dataset to be trained
\item Calculation of performance metrics for the trained model
\end{itemize}

\subsection{Creation of the dataset}
We were able to find an implementation of Siamese Architecture for onle shot learning of omniglot dataset. Omniglot dataset has about 1600 characters with 25 examples for each character.

One shot learning is training the network with least amount of data unlike training DCNNs. As humans we have the ability of one shot learning. For instance if a child shown a spoon once, it has the ability to identify another spoon later on.

Creation of the dataset to be trained on the network that was pre-trained on the omniglot dataset evolved with the following steps:

\begin{itemize}
\item Extracting ads from the channels Discovery, Animal Planet and Fox Life
\subitem Three of the channels are belong to the same family of channels who share same ads so that we can use this for checking for inter-channel ad recognition purpose too.

\subitem The ads were extracted using the logs generated by the current ad monitoring system
\subitem The video streams were captured for the three channels using "Black Magic Media Express"
\subitem The streams captured by the above application were in SDI format so they were compressed by FFMPEG
\subitem The ads extracted using the logs had some start and end point issues. So it was tackled manually.
\subitem Extracted ads were saved frame by frame as jpeg images

\item Equalizing similar ads
\subitem Similar ads should have same number of frames. Because of some technicalities this was not the case. The equalizing task was done manually so that similar ads has the same number of frames with frame by frame correspondence.

\item Similar scene cutting
\subitem This step is the most important step in the process since this is the step that decides whether Siamese Network is fed with right data. First my colleague Vidura Sumanasena wrote a program to figure out scene changes. But later on it was decided to switch to a manual method of similar scene cutting because there's no meaning in using Siamese architecture if we have scene change detection program. The program we used had also human intervention, but not up to the expected level.
\subitem So it was figured out a way to cut similar scenes with the expected level of human intervention. The part where which are similar or not were decided with the help of the terminal program Ranger which proved to be much more productive than the GUI file browsers.
\subitem We had accumulated about 300 advertisements of which about 70 were unique without repetitions. Only of those 70 we had to cut the scenes manually. The rest was automated by a python scripts.
\subitem Finally we achieved about 690 different scenes with more than 20 similar images.
\subitem That dataset was used in the task of training the Siamese Network.

\end{itemize}

\subsection{Performance Metrics Calculations}
After training the pre-trained Siamese network with the ad frames generated, the 200 way Siamese Network was tested on testing data set and the results on table \ref{table:siamese-results} were obtained:
 
\begin{table}[h!]
\caption{Performance metrics of the 200 way Siamese Oneshot task}
\label{table:siamese-results}
\centering

\begin{tabular}{||c| c| c||} 
 \hline
 Precision & Recall & F1 Score \\ [0.5ex] 
 \hline\hline
 $82\%$ & $77\%$ & $80\%$ \\ [1ex] 
 \hline
\end{tabular}


\end{table}

\subsection{What's Next?}
Although Siamese Architecture is proved to be a solution to the ad detection problem, there are some issues yet to tackle:
\begin{itemize}
\item Performance issue
\subitem Since this uses the heavy burden of more than 1 million weights a lots of calculations should be made. Python is not a kind of programming language that can be considered fast.
\subitem The system should be migrated to a industry level realtime applications using a programming language such as c++ or java. 
\subitem The network can be developed using a more efficient framework such as caffe or dl4j.
\item Training issues. 
\subitem Allthough the training is done for about 690 scenes, it is not enough for a model containing more than million parameters.
\subitem At least 2000 scenes should be generated in order to match the order of size of omniglot dataset.
\subitem The training was done to a previously trained model on omniglot dataset. This should not be the case because more advanced techniques like transfer learning can be applied.
\end{itemize}
\subsection{Tools used}

\subsubsection{Ranger}
Ranger is a command line tool for file browsing. This was used in the task of scene creation.

Following some of the advantages of Ranger over other terminal / GUI file browsers.

\begin{itemize}
\item Vim like key mappings. e.g:
\begin{itemize}
\item yy: to copy a file
\item dd: to delete a file
\item G: to go to the end of the folder
\end{itemize}
\subitem These commands were the most used commands in the process of scene generation
\item Image preview
\subitem This was a very useful feature due to the fact that I needed this functionality in order to figure out which scene differ from which. This was an added functionality with the help of \texttt{w3m} browser which is a terminal internet browser which incorporates images on to the terminal
\end{itemize}

\subsubsection{Python}
The python's ability to use as a scripting tool is used a lot in the project.

Following are some the uses of python in this project (except for tasks that are described in earlier projects):

\begin{itemize}
\item File handling and work related to OS. Main modules used:
\begin{itemize}
\item os: python os module has functionality like:
	\begin{itemize}
	\item rename files
	\item move files
	\item delete files
	\item create and read destinations of symbolic links 
	\end{itemize}
\item shutil: this provides shell functionality such as:
	\begin{itemize}
	\item copy files
	\item copy folders
	\end{itemize}
\end{itemize}
\end{itemize}

\subsubsection{Blackmagic Media Express}
Blackmagic media express is a software tool that is shipped with Decklink drivers. It has the following functionalities:

\begin{itemize}
\item Playback feature: If the Decklink SDI 4k card is connected to an input, Media express program has the ability to playbck it in real time. The input can be one of the following formats:
	\begin{itemize}
	\item PAL
	\item NTSC
	\end{itemize}

\item Capture feature: What is inputed can also be captured and saved locally to a file in raw format

\item Screenshot: While the input is playing, screenshots can be taken.
\end{itemize}

One of the downfalls of Media Express is it cannot be accessed by a external program.

\section{Error Reporting System}

This was a request by the Senior Tecnical Officer of DialogTV Ad Insertion Unit Supun Dias. The task was to create an e-mail alert system to report errors occur in the current ad replacement system. The system runs on a java servelet container called Apache Tomcat. It creates log files called "catelina". My task was to create an email alert whenever an error is created in that catelina log files. 

\subsection{Implementation}

This was implemented using a simple python script which either uses secured TLS or SSL for the email service. Following specifications were requested by Mr. Supun.

\begin{itemize}
\item Ability to send to multiple users
\item Ability to easily define rules for error detection
\item Ability to define a timeout such that same errors won't be notified constantly
\item Ability to define a sleep time where the Error Reporting System does not access the log files.
\end{itemize}

This project used the python library \texttt{smtplib} to send emails.

\subsection{What's Next}
The system is currently under operation in DialogTV. But this Error Reporting Sytem can be further developed if they want. For instance Tomcat provides Error reporting internally without that much flexibility. The code written should be refactored more with a proper documentation in order to make it more portable.

\subsection{Tools Used}

\subsubsection{Python}
This is also an occasion where python's scripting capability comes in to play.  It took a very less amount of time to complete this task because all the tools and documentation were available to build the system.

\subsubsection{Jupyter Notebook}
To simulate the catalina error log creating and error notification processes I used Jupyter Notebook, which is an unconventional use of it. Nevertheless it proved to be a great tool to be used in such tasks too.

\section{Final Demonstration Done at DialogTV Premises Kotahena}
This demonstration was done on the 13\textsuperscript{th} of December 2017. The participants were Eng. Darshitha Samarakoon and Mr. Supun Dias, Vidura Sumanasena, Heshan Fernando and myself. 

Vidura showed his work on the ad detection system which was able to tackle
\begin{itemize}
\item inter-cahnnel ad detection problem. 
\item Magic number generation problem
\subitem Magic number generation happens when video frames are either dark or light, generating either values 0, or 255 which will constraint the ability to detect ads.
\item Garbage in frames
\subitem Sometimes in the process of transmission of satellite feed, some signatures are included in addition to the content on the frames.
\subitem Sometimes due to facts like seasonal reasons or offers, several objects on frames are included by the channels.
\item Zooming / aspect ratio changes
\end{itemize}

Eng. Darshitha asked VIdura to try specified amount of:
\begin{itemize}
\item cropped
\item zoomed in
\end{itemize}

videos and they were detected successfully with higher confidence values. Eng. Darshitha and Mr. Supun Dias requested us to:

\begin{itemize}
\item implement his algorithm without removing borders or logos
\item icrease more attention to middle of the frames
\item implement a method to incorporate interest regions on the frames
\item embed Vidura's code on current system
\item add performance improvements
\item make an interface such that the system can be tuned by DialogTV ad insertion unit
\end{itemize}

Heshan presented on our progress on the work on Siamese architecture and SSD Architecture. The main points made were,
\begin{itemize}
\item their susceptibility to inter-channel ad detection
\item their ability to minimize hash space which will lead to space savings
\item the potential of the machine learning architectures for real time ad detection system
\end{itemize}

The demonstration concluded successfully.
